{
  "name": "Open-WebUI",
  "repo": "ghcr.io/open-webui/open-webui:main",
  "category": [ "AI", "Tools", "Network:Web" ],
  "registry": "https://github.com/open-webui/open-webui/pkgs/container/open-webui",
  "network": "bridge",
  "custom_ip": null,
  "default_shell": "bash",
  "privileged": false,
  "extra_parameters": "--restart unless-stopped",
  "post_parameters": null,
  "cpu_set": null,
  "web_ui_url": "http://[ADDRESS]:[PORT:8080]/",
  "icon": "https://raw.githubusercontent.com/open-webui/open-webui/main/static/favicon.png",
  "project": "https://github.com/open-webui/open-webui",
  "support": "https://github.com/open-webui/open-webui/issues",
  "description": "(Formerly Ollama WebUI)\nChatGPT-Style Web Interface for various LLM runners, including Ollama and OpenAI-compatible APIs\n\nIMPORTANT: Make sure to add the following environment variable to your ollama container\n- OLLAMA_ORIGINS=*",
  "paths": [
    {
      "name": "Path: /data",
      "host": "/mnt/user/appdata/open-webui",
      "container": "/app/backend/data",
      "mode": "rw",
      "description": "",
      "required": true
    }
  ],
  "ports": [
    {
      "name": "WebUI",
      "host": "8080",
      "container": "8080",
      "protocol": "tcp",
      "description": "WebUI",
      "required": true,
      "mask": false
    }
  ],
  "variables": [],
  "devices": [],
  "labels": []
}
